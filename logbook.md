#### 2025/07/21  
  复习昨天学习的llm训练范式：GPT和Llama的区别  
  虽然都是基于Transformer架构的自回归语言模型  
  范式为：  
  （GPT）Pretrain、SFT、Reward Model、PPO  
  （Llama）Pretrain、Reward Model、Rejection Sampling、SFT、DPO  
  使用大量无监督文本进行Pretraining  
  两者训练范式的区别在笔记中...
 
#### 2025/07/22
  学习神经网络的基础理论，包括了如下：  
  机器学习的基础 简单的二分类示例  
  使用Mnist数字集，了解了神经网络是一个万金油式的模型，机会可以拟合任何数据。  
  结合机器学习，训练神经网络的参数（参数是如何训练出来的）  
  以及  
  transformer架构，的训练过程：token化、向量化、位置编码、编码器、Linear、softmax  
  整个流程，以及一些小细节的理解  
  补上了Kaplan-Meier模型和Cox危害系数模型的笔记，这两个可以用来写分析和预测用户的流失信息
  
#### 2025/07/23
  补上了使用逻辑回归和DNN模型来预测用户是否流失的项目练习作业  
  
#### 2025/07/24  
  今天梳理了llm应用技术及使用场景，今天学习减少，得好好学习
  
#### 2025/07/25  
  神经网络的前向传播和反向传播的理论  
  tensorflow实战项目 gpu
